{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CARGAMOS EL DATASET DE ENTRENAMIENTO\n",
    "df_train = pd.read_csv(r\"mitbih_train.csv\")\n",
    "\n",
    "df_train.columns = [f'Feature {i + 1}' for i in range(len(df_train.columns) - 1)] + ['Target']\n",
    "df_train\n",
    "\n",
    "# VALIDAMOS LOS VALORES FALTANTES\n",
    "df_train.isnull().sum()\n",
    "\n",
    "# CONTAMOS LOS VALORES DE CADA CLASE\n",
    "df_train['Target'].value_counts()\n",
    "\n",
    "# SEPARAMOS LOS DATOS PREDICTORES Y OBJETIVO\n",
    "X = df_train.drop('Target', axis=1)\n",
    "y = df_train['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0.0    72470\n",
       "4.0     6431\n",
       "2.0     5788\n",
       "1.0     2223\n",
       "3.0      641\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONTAMOS LOS VALORES DE CADA CLASE\n",
    "df_train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\crist\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\crist\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\crist\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\crist\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\crist\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron valores faltantes en el dataset.\n",
      "Distribución de clases antes del submuestreo:\n",
      "Target\n",
      "0.0    72470\n",
      "4.0     6431\n",
      "2.0     5788\n",
      "1.0     2223\n",
      "3.0      641\n",
      "Name: count, dtype: int64\n",
      "Distribución de clases después del submuestreo:\n",
      "Target\n",
      "0.0    641\n",
      "1.0    641\n",
      "2.0    641\n",
      "3.0    641\n",
      "4.0    641\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# CARGAMOS EL DATASET DE ENTRENAMIENTO\n",
    "df_train = pd.read_csv(r\"mitbih_train.csv\")\n",
    "\n",
    "df_train.columns = [f'Feature {i + 1}' for i in range(len(df_train.columns) - 1)] + ['Target']\n",
    "\n",
    "# SEPARAMOS LOS DATOS PREDICTORES (X) Y OBJETIVO (y)\n",
    "X = df_train.iloc[:, :-1]  # Todas las columnas excepto la última (predictores)\n",
    "y = df_train.iloc[:, -1]   # La última columna (objetivo)\n",
    "\n",
    "# VALIDAMOS LOS VALORES FALTANTES\n",
    "if df_train.isnull().sum().sum() > 0:\n",
    "    print(\"Existen valores faltantes en el dataset.\")\n",
    "else:\n",
    "    print(\"No se encontraron valores faltantes en el dataset.\")\n",
    "\n",
    "# CONTAMOS LOS VALORES DE CADA CLASE\n",
    "class_counts = df_train['Target'].value_counts()\n",
    "print(\"Distribución de clases antes del submuestreo:\")\n",
    "print(class_counts)\n",
    "\n",
    "# APLICAMOS RANDOM UNDER SAMPLER PARA BALANCEAR LOS DATOS\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# VERIFICAMOS LA NUEVA DISTRIBUCIÓN DE CLASES\n",
    "print(\"Distribución de clases después del submuestreo:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings as wr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "wr.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\crist\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "# # SEPARAMOS LOS DATOS PREDICTORES Y OBJETIVO\n",
    "# X = df_train.drop('Target', axis=1)\n",
    "# y = df_train['Target']\n",
    "\n",
    "# # LISTA DE MODELOS DE CLASIFICACIÓN QUE VAMOS A UTILIZAR\n",
    "# ls_modelos = [\n",
    "#     ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "#     ('SVM', make_pipeline(StandardScaler(), SVC(random_state=42))),\n",
    "#     ('Logistic Regression', make_pipeline(StandardScaler(), LogisticRegression(random_state=42))),\n",
    "#     ('KNN', make_pipeline(StandardScaler(), KNeighborsClassifier())),\n",
    "#     ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "#     ('Naive Bayes', GaussianNB()),\n",
    "#     ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "#     ('AdaBoost', AdaBoostClassifier(random_state=42))\n",
    "# ]\n",
    "\n",
    "# cv_results = []\n",
    "\n",
    "# # EVALUAMOS CADA UNO DE LOS MODELOS CON CV\n",
    "# for name, model in ls_modelos:\n",
    "#     accuracy_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "#     f1_scores = cross_val_score(model, X, y, cv=5, scoring='f1_macro')\n",
    "#     mse_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "#     cv_results.append({\n",
    "#         'Modelo': name,\n",
    "#         'Mean Accuracy': np.mean(accuracy_scores),\n",
    "#         'Std Accuracy': np.std(accuracy_scores),\n",
    "#         'Mean F1 Score': np.mean(f1_scores),\n",
    "#         'Std F1 Score': np.std(f1_scores),\n",
    "#         'Mean MSE': -np.mean(mse_scores),\n",
    "        \n",
    "#         'Std MSE': np.std(mse_scores)\n",
    "#     })\n",
    "\n",
    "# df_results = pd.DataFrame(cv_results)\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando el modelo: Logistic Regression\n",
      "Evaluando el modelo: K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\crist\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando el modelo: Decision Tree\n",
      "Evaluando el modelo: Random Forest\n",
      "Evaluando el modelo: SVM\n",
      "Evaluando el modelo: Naive Bayes\n",
      "Evaluando el modelo: Gradient Boosting\n",
      "Evaluando el modelo: MLP Classifier\n",
      "\n",
      "Modelo: Logistic Regression\n",
      "Accuracy: 0.7485 ± 0.0097\n",
      "Precision: 0.7478\n",
      "Recall: 0.7485\n",
      "F1 Score: 0.7472\n",
      "\n",
      "Modelo: K-Nearest Neighbors\n",
      "Accuracy: 0.8365 ± 0.0137\n",
      "Precision: 0.8377\n",
      "Recall: 0.8365\n",
      "F1 Score: 0.8366\n",
      "\n",
      "Modelo: Decision Tree\n",
      "Accuracy: 0.7931 ± 0.0081\n",
      "Precision: 0.7928\n",
      "Recall: 0.7931\n",
      "F1 Score: 0.7923\n",
      "\n",
      "Modelo: Random Forest\n",
      "Accuracy: 0.8864 ± 0.0111\n",
      "Precision: 0.8914\n",
      "Recall: 0.8864\n",
      "F1 Score: 0.8876\n",
      "\n",
      "Modelo: SVM\n",
      "Accuracy: 0.7760 ± 0.0124\n",
      "Precision: 0.7858\n",
      "Recall: 0.7760\n",
      "F1 Score: 0.7784\n",
      "\n",
      "Modelo: Naive Bayes\n",
      "Accuracy: 0.2855 ± 0.0110\n",
      "Precision: 0.3954\n",
      "Recall: 0.2855\n",
      "F1 Score: 0.2128\n",
      "\n",
      "Modelo: Gradient Boosting\n",
      "Accuracy: 0.8534 ± 0.0093\n",
      "Precision: 0.8571\n",
      "Recall: 0.8533\n",
      "F1 Score: 0.8541\n",
      "\n",
      "Modelo: MLP Classifier\n",
      "Accuracy: 0.8615 ± 0.0174\n",
      "Precision: 0.8618\n",
      "Recall: 0.8615\n",
      "F1 Score: 0.8611\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Lista de modelos para evaluar\n",
    "modelos = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'MLP Classifier': MLPClassifier(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "resultados = {}\n",
    "\n",
    "# Evaluación de cada modelo con validación cruzada\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f'Evaluando el modelo: {nombre}')\n",
    "    \n",
    "    # Validación cruzada con 5 folds (puedes cambiar el número de folds)\n",
    "    scores = cross_val_score(modelo, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Guardamos los resultados\n",
    "    resultados[nombre] = {\n",
    "        'mean_accuracy': scores.mean(),\n",
    "        'std_accuracy': scores.std()\n",
    "    }\n",
    "\n",
    "    # Métricas adicionales\n",
    "    precision = cross_val_score(modelo, X_resampled, y_resampled, cv=5, scoring='precision_macro').mean()\n",
    "    recall = cross_val_score(modelo, X_resampled, y_resampled, cv=5, scoring='recall_macro').mean()\n",
    "    f1 = cross_val_score(modelo, X_resampled, y_resampled, cv=5, scoring='f1_macro').mean()\n",
    "    \n",
    "    # Guardamos las métricas adicionales\n",
    "    resultados[nombre]['precision'] = precision\n",
    "    resultados[nombre]['recall'] = recall\n",
    "    resultados[nombre]['f1_score'] = f1\n",
    "\n",
    "# Mostrar resultados\n",
    "for nombre, metricas in resultados.items():\n",
    "    print(f\"\\nModelo: {nombre}\")\n",
    "    print(f\"Accuracy: {metricas['mean_accuracy']:.4f} ± {metricas['std_accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metricas['precision']:.4f}\")\n",
    "    print(f\"Recall: {metricas['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metricas['f1_score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
