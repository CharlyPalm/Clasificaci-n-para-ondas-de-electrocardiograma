{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron valores faltantes en el dataset.\n",
      "Distribución de clases antes del submuestreo:\n",
      "Target\n",
      "0.0    72470\n",
      "4.0     6431\n",
      "2.0     5788\n",
      "1.0     2223\n",
      "3.0      641\n",
      "Name: count, dtype: int64\n",
      "Distribución de clases después del submuestreo:\n",
      "Target\n",
      "0.0    641\n",
      "1.0    641\n",
      "2.0    641\n",
      "3.0    641\n",
      "4.0    641\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# CARGAMOS EL DATASET DE ENTRENAMIENTO\n",
    "df_train = pd.read_csv(r\"mitbih_train.csv\")\n",
    "\n",
    "df_train.columns = [f'Feature {i + 1}' for i in range(len(df_train.columns) - 1)] + ['Target']\n",
    "\n",
    "# SEPARAMOS LOS DATOS PREDICTORES (X) Y OBJETIVO (y)\n",
    "X = df_train.iloc[:, :-1]  # Todas las columnas excepto la última (predictores)\n",
    "y = df_train.iloc[:, -1]   # La última columna (objetivo)\n",
    "\n",
    "# VALIDAMOS LOS VALORES FALTANTES\n",
    "if df_train.isnull().sum().sum() > 0:\n",
    "    print(\"Existen valores faltantes en el dataset.\")\n",
    "else:\n",
    "    print(\"No se encontraron valores faltantes en el dataset.\")\n",
    "\n",
    "# CONTAMOS LOS VALORES DE CADA CLASE\n",
    "class_counts = df_train['Target'].value_counts()\n",
    "print(\"Distribución de clases antes del submuestreo:\")\n",
    "print(class_counts)\n",
    "\n",
    "# APLICAMOS RANDOM UNDER SAMPLER PARA BALANCEAR LOS DATOS\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# VERIFICAMOS LA NUEVA DISTRIBUCIÓN DE CLASES\n",
    "print(\"Distribución de clases después del submuestreo:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings as wr\n",
    "wr.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 179</th>\n",
       "      <th>Feature 180</th>\n",
       "      <th>Feature 181</th>\n",
       "      <th>Feature 182</th>\n",
       "      <th>Feature 183</th>\n",
       "      <th>Feature 184</th>\n",
       "      <th>Feature 185</th>\n",
       "      <th>Feature 186</th>\n",
       "      <th>Feature 187</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0   0.960114   0.863248   0.461538   0.196581   0.094017   0.125356   \n",
       "1   1.000000   0.659459   0.186486   0.070270   0.070270   0.059459   \n",
       "2   0.925414   0.665746   0.541436   0.276243   0.196133   0.077348   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 179  Feature 180  \\\n",
       "0   0.099715   0.088319   0.074074    0.082621  ...          0.0          0.0   \n",
       "1   0.056757   0.043243   0.054054    0.045946  ...          0.0          0.0   \n",
       "2   0.071823   0.060773   0.066298    0.058011  ...          0.0          0.0   \n",
       "\n",
       "   Feature 181  Feature 182  Feature 183  Feature 184  Feature 185  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Feature 186  Feature 187  Target  \n",
       "0          0.0          0.0     0.0  \n",
       "1          0.0          0.0     0.0  \n",
       "2          0.0          0.0     0.0  \n",
       "\n",
       "[3 rows x 188 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set classes:  [0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "print('train set classes: ', df_train.iloc[:, -1].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se conservaron los nombres del ejercicio 1 para poder reutilizar los códigos disminuyendo el número de modificcaciones\n",
    "X_resampled = X.to_numpy()\n",
    "y_resampled = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosting Classifier - Hyperparameter tuning -----\n",
      "---- n_estimators = 50, learning_rate = 0.010\n",
      "ACC: 0.8807236479339853\n",
      "---- n_estimators = 50, learning_rate = 0.031\n",
      "ACC: 0.934005669146009\n",
      "---- n_estimators = 50, learning_rate = 0.052\n",
      "ACC: 0.9477002348299564\n",
      "---- n_estimators = 50, learning_rate = 0.073\n",
      "ACC: 0.9543590604597043\n",
      "---- n_estimators = 50, learning_rate = 0.094\n",
      "ACC: 0.9574314860780501\n",
      "---- n_estimators = 50, learning_rate = 0.116\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# Parámetros del clasificador Gradient Boosting\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"----- Gradient Boosting Classifier - Hyperparameter tuning -----\")\n",
    "\n",
    "n_estimators_range = np.arange(50, 201, 10)  # Rango para el número de estimadores\n",
    "learning_rate_range = np.linspace(0.01, 0.2, 10)  # Rango para la tasa de aprendizaje\n",
    "best_acc = 0\n",
    "best_params = {}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Búsqueda de los mejores hiperparámetros\n",
    "for n_estimators in n_estimators_range:\n",
    "    for learning_rate in learning_rate_range:\n",
    "        print(f'---- n_estimators = {n_estimators}, learning_rate = {learning_rate:.3f}')\n",
    "        \n",
    "        acc_cv = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_resampled, y_resampled):\n",
    "            # Fase de entrenamiento\n",
    "            x_train = X_resampled[train_index, :]\n",
    "            y_train = y_resampled[train_index]\n",
    "            \n",
    "            clf_cv = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)\n",
    "            clf_cv.fit(x_train, y_train)\n",
    "            \n",
    "            # Fase de prueba\n",
    "            x_test = X_resampled[test_index, :]\n",
    "            y_test = y_resampled[test_index]\n",
    "            y_pred = clf_cv.predict(x_test)\n",
    "            \n",
    "            acc_i = accuracy_score(y_test, y_pred)\n",
    "            acc_cv.append(acc_i)\n",
    "        \n",
    "        # Promedio de las precisiones en las 5 particiones\n",
    "        acc_hyp = np.mean(acc_cv)\n",
    "        \n",
    "        # Guardamos los mejores hiperparámetros\n",
    "        if acc_hyp > best_acc:\n",
    "            best_acc = acc_hyp\n",
    "            best_params = {'n_estimators': n_estimators, 'learning_rate': learning_rate}\n",
    "        \n",
    "        print('ACC:', acc_hyp)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(\"n_estimators:\", best_params['n_estimators'])\n",
    "print(\"learning_rate:\", best_params['learning_rate'])\n",
    "print(\"Mejor precisión:\", best_acc)\n",
    "\n",
    "# Entrenamos el modelo final con los mejores hiperparámetros\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], random_state=42)\n",
    "clf_gb.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## función de carlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    f1_scorer = make_scorer(f1_score, average='macro')\n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "    print(f'F1 Score: {scores.mean():.4f}')\n",
    "    \n",
    "\n",
    "\n",
    "    # Ajuste del modelo\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='viridis')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------- Evaluando GB --------')\n",
    "evaluate_model(GradientBoostingClassifier(), X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
